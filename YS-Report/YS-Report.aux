\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{ii}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Specification}{ii}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Pseudocode}{iii}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Flowchart for the general Spam Classification process\relax }}{iv}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:flowchart}{{1}{iv}}
\citation{schutze2008introduction}
\citation{jabeen2018stem}
\citation{fortney2017nlp}
\citation{schutze2008introduction}
\@writefile{toc}{\contentsline {section}{\numberline {3}Pre-Processing}{v}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Lemmatization}{v}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Showing the mapping of words to its lemma\relax }}{v}}
\newlabel{table: lemma}{{1}{v}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Removal of Stop Words}{v}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Removal of Punctuation}{v}}
\citation{svm}
\citation{ray2017svm}
\citation{hofmann2008kernel}
\citation{randforest}
\@writefile{toc}{\contentsline {section}{\numberline {4}Machine Learning Methods}{vi}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Support Vector Machine}{vi}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces SVM on 2-D plot area\relax }}{vi}}
\newlabel{fig:svm}{{2}{vi}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Kernel feature of SVM\relax }}{vi}}
\newlabel{fig:svm_kernel}{{3}{vi}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Random Forest}{vi}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Multilayer Perceptron}{vi}}
\citation{sakkis2003memory}
\citation{enron}
\citation{accuracy}
\@writefile{toc}{\contentsline {section}{\numberline {5}Datasets Used}{vii}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Ling-Spam Dataset}{vii}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Enron Dataset}{vii}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Measurement Metrics}{vii}}
\citation{precision_recall}
\citation{precision_recall}
\citation{f1}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Accuracy}{viii}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Precision}{viii}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Recall}{viii}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}F1-Score}{viii}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Results and Discussion}{viii}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Results on Ling-Spam data}{ix}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Table showing results for machine learning models on Ling-Spam dataset\relax }}{ix}}
\newlabel{table:lingspam}{{2}{ix}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Results on Enron data}{x}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Table showing results for machine learning models on Enron dataset\relax }}{x}}
\newlabel{table:enron}{{3}{x}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Discussion}{x}}
\bibdata{references}
\bibcite{schutze2008introduction}{1}
\bibcite{jabeen2018stem}{2}
\bibcite{fortney2017nlp}{3}
\bibcite{svm}{4}
\bibcite{ray2017svm}{5}
\bibcite{hofmann2008kernel}{6}
\bibcite{randforest}{7}
\bibcite{sakkis2003memory}{8}
\bibcite{enron}{9}
\bibcite{accuracy}{10}
\bibcite{precision_recall}{11}
\bibcite{f1}{12}
\bibstyle{ieeetr}
\@writefile{toc}{\contentsline {section}{\numberline {A}Code}{xii}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}utility.py}{xii}}
\@writefile{lol}{\contentsline {lstlisting}{utility.py}{xii}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}spam\textunderscore classifier.py}{xvi}}
\@writefile{lol}{\contentsline {lstlisting}{spam\textunderscore classifier.py}{xvi}}
